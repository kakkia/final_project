{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "streamlit_app.ipynb",
      "provenance": [],
      "mount_file_id": "1CQSOBHpoL1h_G5bATRrFHzVS4TCU3pqy",
      "authorship_tag": "ABX9TyMpfaSg28KUWk7ILOcoQc67",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kakkia/final_project/blob/main/saved_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XQOkaqcq5TO7"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import joblib\n",
        "from keras.preprocessing import image\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "\n",
        "data = \"/content/drive/MyDrive/dataset\"\n",
        "train_ds = pathlib.Path(data)\n",
        "validation = \"/content/drive/MyDrive/validation\"\n",
        "val_ds = pathlib.Path(validation)"
      ],
      "metadata": {
        "id": "ZRsiBWWs5X2G"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "metadata": {
        "id": "0bBYGBn15_VI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = tf.keras.utils.image_dataset_from_directory(\n",
        "  train_ds,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size\n",
        "  )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naQGnGzs5lIR",
        "outputId": "e4c57db5-2478-41c2-96d0-ea5b9a90e004"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1007 files belonging to 3 classes.\n",
            "Using 806 files for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = tf.keras.utils.image_dataset_from_directory(\n",
        "  train_ds,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTYwN6gy6Tbp",
        "outputId": "6d5f8b5c-ca79-48f1-8263-3d4a63d95594"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1007 files belonging to 3 classes.\n",
            "Using 201 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_images.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcLBL-9V5qXb",
        "outputId": "01cb8b8f-3a1e-4f08-a8ee-ca566384e7f7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['perfect', 'shoo', 'what']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_layer = layers.Rescaling(1./255)\n",
        "\n",
        "normalized_ds = train_images.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "# Notice the pixel values are now in `[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSqy96NH5wt3",
        "outputId": "df16f960-2aee-4542-db32-216a58ca2bc7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.21960786 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple sequential model\n",
        "\n",
        "def create_model():\n",
        "  model = Sequential([\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu', input_shape=(img_height, img_width, 3)),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(3)\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=[tf.metrics.SparseCategoricalAccuracy()])\n",
        "\n",
        "  return model\n",
        "\n",
        "# Create a basic model instance\n",
        "model = create_model()\n",
        "\n",
        "# Display the model's architecture\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czDdQPCK5X4a",
        "outputId": "1c538b8b-35f7-42c0-d24b-7e300eb44390"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 180, 180, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 90, 90, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 90, 90, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 45, 45, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 45, 45, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 22, 22, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 30976)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               3965056   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,989,027\n",
            "Trainable params: 3,989,027\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"training_1/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "# Train the model with the new callback\n",
        "model.fit(train_images, \n",
        "          epochs=10,\n",
        "          validation_data=(test_images),\n",
        "          callbacks=[cp_callback])  # Pass callback to training\n",
        "\n",
        "# This may generate warnings related to saving the state of the optimizer.\n",
        "# These warnings (and similar warnings throughout this notebook)\n",
        "# are in place to discourage outdated usage, and can be ignored."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57attJMa5Yf2",
        "outputId": "10cdda39-b51a-4b30-e476-e321b911327b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "26/26 [==============================] - ETA: 0s - loss: 145.4824 - sparse_categorical_accuracy: 0.4442\n",
            "Epoch 1: saving model to training_1/cp.ckpt\n",
            "26/26 [==============================] - 111s 4s/step - loss: 145.4824 - sparse_categorical_accuracy: 0.4442 - val_loss: 0.7220 - val_sparse_categorical_accuracy: 0.7363\n",
            "Epoch 2/10\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.4704 - sparse_categorical_accuracy: 0.8114\n",
            "Epoch 2: saving model to training_1/cp.ckpt\n",
            "26/26 [==============================] - 24s 911ms/step - loss: 0.4704 - sparse_categorical_accuracy: 0.8114 - val_loss: 0.5684 - val_sparse_categorical_accuracy: 0.8308\n",
            "Epoch 3/10\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.4525 - sparse_categorical_accuracy: 0.8201\n",
            "Epoch 3: saving model to training_1/cp.ckpt\n",
            "26/26 [==============================] - 24s 902ms/step - loss: 0.4525 - sparse_categorical_accuracy: 0.8201 - val_loss: 0.6271 - val_sparse_categorical_accuracy: 0.7015\n",
            "Epoch 4/10\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.2563 - sparse_categorical_accuracy: 0.9020\n",
            "Epoch 4: saving model to training_1/cp.ckpt\n",
            "26/26 [==============================] - 24s 908ms/step - loss: 0.2563 - sparse_categorical_accuracy: 0.9020 - val_loss: 0.5122 - val_sparse_categorical_accuracy: 0.8458\n",
            "Epoch 5/10\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.1078 - sparse_categorical_accuracy: 0.9578\n",
            "Epoch 5: saving model to training_1/cp.ckpt\n",
            "26/26 [==============================] - 24s 908ms/step - loss: 0.1078 - sparse_categorical_accuracy: 0.9578 - val_loss: 0.6837 - val_sparse_categorical_accuracy: 0.7910\n",
            "Epoch 6/10\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.1220 - sparse_categorical_accuracy: 0.9529\n",
            "Epoch 6: saving model to training_1/cp.ckpt\n",
            "26/26 [==============================] - 24s 904ms/step - loss: 0.1220 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.6833 - val_sparse_categorical_accuracy: 0.8458\n",
            "Epoch 7/10\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.0567 - sparse_categorical_accuracy: 0.9876\n",
            "Epoch 7: saving model to training_1/cp.ckpt\n",
            "26/26 [==============================] - 24s 907ms/step - loss: 0.0567 - sparse_categorical_accuracy: 0.9876 - val_loss: 0.5532 - val_sparse_categorical_accuracy: 0.8706\n",
            "Epoch 8/10\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.2521 - sparse_categorical_accuracy: 0.9144\n",
            "Epoch 8: saving model to training_1/cp.ckpt\n",
            "26/26 [==============================] - 24s 906ms/step - loss: 0.2521 - sparse_categorical_accuracy: 0.9144 - val_loss: 0.7286 - val_sparse_categorical_accuracy: 0.7214\n",
            "Epoch 9/10\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.1632 - sparse_categorical_accuracy: 0.9467\n",
            "Epoch 9: saving model to training_1/cp.ckpt\n",
            "26/26 [==============================] - 24s 910ms/step - loss: 0.1632 - sparse_categorical_accuracy: 0.9467 - val_loss: 0.9076 - val_sparse_categorical_accuracy: 0.8109\n",
            "Epoch 10/10\n",
            "26/26 [==============================] - ETA: 0s - loss: 0.1037 - sparse_categorical_accuracy: 0.9764\n",
            "Epoch 10: saving model to training_1/cp.ckpt\n",
            "26/26 [==============================] - 24s 906ms/step - loss: 0.1037 - sparse_categorical_accuracy: 0.9764 - val_loss: 0.7376 - val_sparse_categorical_accuracy: 0.8159\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f86bbca43d0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(checkpoint_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOKhVAI95a_W",
        "outputId": "b032b69e-1367-41d4-86c5-fe48e48d42de"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['checkpoint', 'cp.ckpt.index', 'cp.ckpt.data-00000-of-00001']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now rebuild a fresh, untrained model and evaluate it on the test set. An untrained model will perform at chance levels (~10% accuracy):\n",
        "\n",
        "#Create a basic model instance\n",
        "model = create_model()\n",
        "\n",
        "# Evaluate the model\n",
        "loss, acc = model.evaluate(test_images, verbose=2)\n",
        "print(\"Untrained model, accuracy: {:5.2f}%\".format(100 * acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovG5BQzP7Mgp",
        "outputId": "01c57868-10bd-439c-f9e6-91c830e6190e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 - 2s - loss: 15.8519 - sparse_categorical_accuracy: 0.3781 - 2s/epoch - 297ms/step\n",
            "Untrained model, accuracy: 37.81%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Then load the weights from the checkpoint and re-evaluate:\n",
        "\n",
        "#Loads the weights\n",
        "model.load_weights(checkpoint_path)\n",
        "\n",
        "# Re-evaluate the model\n",
        "loss, acc = model.evaluate(test_images, verbose=2)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qPuLR_r7Mkk",
        "outputId": "d9033083-b187-468e-ef07-d6f43d56ac16"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 - 2s - loss: 0.7376 - sparse_categorical_accuracy: 0.8159 - 2s/epoch - 287ms/step\n",
            "Restored model, accuracy: 81.59%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/my_model/hand_gestures.h5\")"
      ],
      "metadata": {
        "id": "wzknKTrDgUuJ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a new model, and save uniquely named checkpoints once every five epochs:\n",
        "\n",
        "#Include the epoch in the file name (uses `str.format`)\n",
        "\n",
        "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create a callback that saves the model's weights every 5 epochs\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    save_freq=5*batch_size)\n",
        "\n",
        "# Create a new model instance\n",
        "model = create_model()\n",
        "\n",
        "# Save the weights using the `checkpoint_path` format\n",
        "model.save_weights(checkpoint_path.format(epoch=0))\n",
        "\n",
        "# Train the model with the new callback\n",
        "model.fit(train_images, \n",
        "          epochs=50, \n",
        "          batch_size=batch_size, \n",
        "          callbacks=[cp_callback],\n",
        "          validation_data=(test_images),\n",
        "          verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzoQ34Fx9fIA",
        "outputId": "819a6c0c-8847-48f6-9e3b-622a0e795806"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7: saving model to training_2/cp-0007.ckpt\n",
            "\n",
            "Epoch 13: saving model to training_2/cp-0013.ckpt\n",
            "\n",
            "Epoch 19: saving model to training_2/cp-0019.ckpt\n",
            "\n",
            "Epoch 25: saving model to training_2/cp-0025.ckpt\n",
            "\n",
            "Epoch 31: saving model to training_2/cp-0031.ckpt\n",
            "\n",
            "Epoch 37: saving model to training_2/cp-0037.ckpt\n",
            "\n",
            "Epoch 44: saving model to training_2/cp-0044.ckpt\n",
            "\n",
            "Epoch 50: saving model to training_2/cp-0050.ckpt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f99d077f290>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# look at resulting checkpoints \n",
        "\n",
        "os.listdir(checkpoint_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDCvy-9M7Mn-",
        "outputId": "19e1eee3-6552-4838-c172-bf6c5b40271f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cp-0000.ckpt.data-00000-of-00001',\n",
              " 'cp-0031.ckpt.data-00000-of-00001',\n",
              " 'cp-0019.ckpt.data-00000-of-00001',\n",
              " 'cp-0019.ckpt.index',\n",
              " 'cp-0037.ckpt.index',\n",
              " 'checkpoint',\n",
              " 'cp-0007.ckpt.index',\n",
              " 'cp-0007.ckpt.data-00000-of-00001',\n",
              " 'cp-0025.ckpt.index',\n",
              " 'cp-0037.ckpt.data-00000-of-00001',\n",
              " 'cp-0025.ckpt.data-00000-of-00001',\n",
              " 'cp-0044.ckpt.index',\n",
              " 'cp-0013.ckpt.index',\n",
              " 'cp-0000.ckpt.index',\n",
              " 'cp-0013.ckpt.data-00000-of-00001',\n",
              " 'cp-0050.ckpt.data-00000-of-00001',\n",
              " 'cp-0044.ckpt.data-00000-of-00001',\n",
              " 'cp-0050.ckpt.index',\n",
              " 'cp-0031.ckpt.index']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "latest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "gp0kY6bQ92Vi",
        "outputId": "08742374-eefb-476b-9dac-56c95b32e2de"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'training_2/cp-0050.ckpt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To test, reset the model and load the latest checkpoint:\n",
        "\n",
        "# Create a new model instance\n",
        "model = create_model()\n",
        "\n",
        "# Load the previously saved weights\n",
        "model.load_weights(latest)\n",
        "\n",
        "# Re-evaluate the model\n",
        "loss, acc = model.evaluate(test_images, verbose=2)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00_G7NcI94cO",
        "outputId": "4e901c90-d684-4254-b9ed-cfdf837188c8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 - 3s - loss: 0.7772 - sparse_categorical_accuracy: 0.8955 - 3s/epoch - 359ms/step\n",
            "Restored model, accuracy: 89.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/my_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qma1X3ag99fJ",
        "outputId": "8995ab32-ea79-4fc4-d464-92cc8981107a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/my_model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xlWzwz-ifnF3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}